{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### posible action : \n",
    "- left , right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enviroment space : \n",
    "- position of cart\n",
    "- velocity of cart\n",
    "- angle of the pole to the verticle\n",
    "- angular velocity in which the pole is moving\n",
    "\n",
    "> low : give lower bounds of 4 values that make up the observation space (individual state variable cannot have values below these)\n",
    "\n",
    "> high : give upper bounds of 4 values that make up the observation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretize the state space :\n",
    "> so we can apply Q_Learning to bounded space \n",
    "> (this is a technique to reduce dimentionality Q_value computation)\n",
    "\n",
    "- position of cart (Left , Right)\n",
    "> 1: ignoring this variable completely in our state space\n",
    "- velocity of cart\n",
    "> 1: ignoring this variable completely in our state space\n",
    "- angle of the pole to the verticle\n",
    "- angular velocity in which the pole is moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## two first 1 refer to ignoring 2 dimention of state space\n",
    "## 6 bucket refer to 6 discrete intervals\n",
    "NUM_BUCKETS  = ( 1 , 1 , 6 , 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ACTION   = env.action_space.n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_BOUNDS = list(zip(env.observation_space.low,env.observation_space.high))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### redefine some of bounds in order to further limit our state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-4.8, 4.8),\n",
       " [-0.5, 0.5],\n",
       " (-0.41887903, 0.41887903),\n",
       " [-0.8726646259971648, 0.8726646259971648]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATE_BOUNDS[1] = [-.5 , .5]\n",
    "STATE_BOUNDS[3] = [-math.radians(50) , math.radians(50)]\n",
    "\n",
    "STATE_BOUNDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize Q_Table :\n",
    "\n",
    "#### num_states × num_actions = (1,1,3,6)×2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Q_Table : (1, 1, 6, 3, 2)\n",
      "\n",
      "[[[[[0. 0.]\n",
      "    [0. 0.]\n",
      "    [0. 0.]]\n",
      "\n",
      "   [[0. 0.]\n",
      "    [0. 0.]\n",
      "    [0. 0.]]\n",
      "\n",
      "   [[0. 0.]\n",
      "    [0. 0.]\n",
      "    [0. 0.]]\n",
      "\n",
      "   [[0. 0.]\n",
      "    [0. 0.]\n",
      "    [0. 0.]]\n",
      "\n",
      "   [[0. 0.]\n",
      "    [0. 0.]\n",
      "    [0. 0.]]\n",
      "\n",
      "   [[0. 0.]\n",
      "    [0. 0.]\n",
      "    [0. 0.]]]]]\n"
     ]
    }
   ],
   "source": [
    "q_table = np.zeros(NUM_BUCKETS+(NUM_ACTION,))\n",
    "print(\"shape of Q_Table : {}\\n\".format(q_table.shape))\n",
    "print(q_table)\n",
    "\n",
    "### first 4 dimention refer to states\n",
    "### last dimention refer to actions for each state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we initially want to explore state space in order to fill up the Q-value in Q_Table\n",
    "- we use an explanatory rate of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPLORATION_RATE_MIN = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE_MIN =  0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
